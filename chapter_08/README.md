# Chapter 08. '정확히 한 번' 의미 구조
* 카프카의 '정확히 한 번' 의미 구조는 두 개의 핵심 기능인 멱등적 프로듀서와 트랜잭션 의미 구조의 조합으로 나누어진다.
* 멱등적 프로듀서는 재시도로 인해 발생하는 중복을 방지한다.
* 트랜잭션 의미 구조는 스트림 처리 애플리케이션에서 '정확히 한 번' 처리를 보장한다.

## 8.1 멱등적 프로듀서
* 동일한 작업을 여러 번 실행해도 한 번 실행한 것과 결과가 같은 서비스를 멱등(idempotent)하다고 한다.
```text
1. UPDATE t SET x=x+1 where y = 5
2. UPDATE t SET x=8 where y = 5
```
* 1은 멱등하지 않고, 2는 멱등하다. 1은 여러 번 호출되면 결과가 달라지고, 2는 항상 같기 때문이다.
* 카프카에서 프로듀서는 메시지 전송을 재시도함으로써 메시지가 최소 한 번 이상 도착하는 불확실성이 존재하게 된다. 이러한 재시도는 메시지 중복을 발생시킬 수 있다.
```text
고전적으로 아래와 같은 상황이 있을 수 있다.
1. 파티션 리더가 프로듀서로부터 레코드를 받아서 팔로워들에게 성공적으로 복제한다.
2. 프로듀서에게 응답을 보내기 전, 파티션 리더가 있는 브로커에 크래시가 발생한다.
3. 프로듀서 입자엥서는 응답을 받지 못한 채 타임아웃이 발생하고, 메시지를 재전송한다.
4. 재전송된 메시지가 새 리더에 도착한다. 하지만 이 메시지는 이미 저장되어 있다. (결과적으로, 중복이 발생한다.)
```

### 8.1.1 멱등적 프로듀서의 작동 원리
* 멱등적 프로듀서 기능을 켜면 모든 메시지는 고유한 프로듀서 ID와 시퀀스 넘버를 가지게 된다.
  * 대상 토픽 및 파티션과 위 두 값을 합치면 각 메시지의 고유한 식별자가 된다.
  * 각 브로커는 해당 브로커에 할당된 모든 파티션들에 쓰여진 마지막 5개 메시지들을 추적하기 위해 이 고유 식별자를 사용한다.
  * 파티션별로 추적되어야 하는 시퀀스 넘버의 수를 제한하고 싶다면 프로듀서의 max.in.flights.requests.per.connection 설정값이 5 이하로 잡혀 있어야 한다. (기본값: 5)
* 브로커가 예전에 받은 적이 있는 메시지를 받게 될 경우, 적절한 에러를 발생시킴으로써 중복 메시지를 거부한다.
  * 이 에러는 프로듀서에 로깅도 되고 지푯값에도 반영이 되지만, 예외가 발생하는 것은 아니기 때문에 사용자에게 경보를 보내지 않는다.
  * 프로듀서 클라이언트에서는 record-error-rate 지푯값을 확인함으로써 에러를 확인할 수 있다.
  * 브로커의 경우 RequestMetrics 유형의 ErrorsPerSec 지푯값에 기록된다.
* 만약 브로커가 예상보다 높은 시퀀스 넘버를 받게 된다면 'out of order sequence number' 에러를 발생시킨다. (2번 메시지 다음에 3번 메시지가 올 것을 예쌍했지만, 27번 메시지가 오는 경우)
  * 트랜잭션 기능 없이 멱등적 프로듀서만 사용하고 있다면 이 에러는 무시해도 괜찮다.
  * 'out of order sequence number' 에러가 발생한 뒤에도 프로듀서가 정상 작동한다면, 이 에러는 보통 프로듀서와 브로커 사이에 메시지 유실이 있었음을 의미한다.
  * 이러한 경우 프로듀서 설정이 고신뢰성을 위해 권장되는 값으로 잡혀 있는지, 아니면 언클린 리더 선출이 발생했는지의 여부를 확인해 볼 필요가 있다.

#### 프로듀서 재시작과 브로커 장애가 발생하는 경우에는 어떻게 될까?
1. 프로듀서 재시작
* 프로듀서 장애로 인해 재시작 될 때, 멱등적 프로듀서 기능이 켜져 있을 경우, 프로듀서는 초기화 과정에서 카프카 브로커로부터 프로듀서 ID를 생성받는다.
  * 트랜잭션 기능이 켜져 있지 않을 경우, 프로듀서를 초기화할 때마다 새로운 ID가 생성된다. 
  * 즉, 새로운 프로듀서가 기존 프로듀서가 이미 전송한 메시지를 다시 전송할 경우, 브로커는 메시지에 중복이 발생했음을 알아차리지 못한다. (두 메시지가 서로 다른 프로듀서 ID와 시퀀스 넘버를 갖기 때문에 서로 다른 것으로 취급될 것이기 때문이다.)
* 기존 프로듀서가 작동을 멈췄다가 새 프로듀서가 투입된 뒤 작동을 재개한 경우에도 서로 다른 ID를 가진 서로 다른 프로듀서로 간주되기 때문에 기존 프로듀서는 좀비로 취급되지 않는다.

2. 브로커 장애
* 브로커 장애가 발생한 경우, 컨트롤러는 장애가 난 브로커가 리더를 맡고 있었던 파티션들에 대해 새 리더를 선출한다.
```text
example.
* 토픽 A의 파티션 0에 메시지를 쓰는 프로듀서를 가지고 있는 상황
* 이 파티션의 리더 레플리카는 브로커 5에 있고, 팔로워 레플리카는 브로커 3에 있다.
* 브로커 5에 장애가 발생하면, 브로커 3이 새로운 리더가 된다. 프로듀서는 메타데이터 프로토콜을 통해 브로커 3이 새 리더임을 알아차리고 그 곳으로 메시지를 쓰기 시작한다.
```
* 브로커 3의 입장에서, 어느 시퀀스 넘버까지 쓰여졌는지 어떻게 알고 중복을 걸러낼까?
  * 리더는 새 메시지가 쓰여질 때마다 인-메모리 프로듀서 상태에 저장된 최근 5개의 시퀀스 넘버를 업데이트한다.
  * 팔로워 레플리카는 리더로부터 새로운 메시지를 복제할 때마다 자체적인 인-메모리 버퍼를 업데이트한다. 즉, 팔로워가 리더가 된 시점에는 이미 메모리 안에 최근 5개의 시퀀스 넘버를 가지고 있는 것이다.
  * 따라서 이슈나 지연 없이, 새로 쓰여진 메시지의 유효성 검증이 재개될 수 있는 것이다.
* 하지만, 예전 리더가 다시 돌아온다면?
  * 재시작 후에는 인-메모리 프로듀서 상태는 더 이상 메모리 안에 저장되어 있지 않다.
  * 복구 과정에 도움이 될 수 있도록, 브로커는 종료되거나 새 세그먼트가 생성될 때마다 프로듀서 상태에 대한 스냅샷 파일 형태로 저장한다.
  * 브로커가 시작되면 일단 파일에서 최신 상태를 읽어오고, 현재 리더로부터 복제한 레코드를 사용해서 프로듀서 상태를 업데이트함으로써 최신 상태를 복구한다.
  * 이 브로커가 다시 리더를 맡을 준비가 될 시점에는 최신 시퀀스 넘버를 가지고 있게 된다.
* 만약 브로커가 크래시가 나서 최신 스냅샷이 업데이트되지 않는다면 어떻게 될까?
  * 프로듀서 ID와 시퀀스 넘버는 둘 다 카프카 로그에 저장되는 메시지 형식의 일부다.
  * 크래시 복구 작업이 진행되는 동안 프로듀서 상태는 더 오래 된 스냅샷뿐만 아니라 각 파티션 최신 세그먼트의 메시지들 역시 사용해서 복구된다.
  * 복구 작업이 완료되는 대로 새로운 스냅샷 파일이 저장된다.

### 8.1.2 멱등적 프로듀서의 한계
* 카프카의 멱등적 프로듀서는 프로듀서의 내부 로직으로 인한 재시도가 발생한 경우에 생기는 중복만을 방지한다.
  * 동일한 메시지를 가지고 producer.send()를 두 번 호출하면 멱등적 프로듀서가 개입하지 않는 만큼 중복된 메시지가 생기게 된다.
  * 프로듀서 예외를 잡아서 애플리케이션이 직접 재시도하는 것보다는 프로듀서에 탑재된 재시도 메커니즘을 사용하는 것이 언제나 낫다.

### 8.1.3 멱등적 프로듀서 사용법
* 프로듀서 설정에 enable.idempotence=true 를 추가해주면 끝이다. (카프카 3.0부터는 기본값으로 켜져있다.)
* 만약 프로듀서에 acks=all 설정이 이미 잡혀 있다면, 성능에는 차이가 없다. (카프카 3.0부터는 기본값으로 all로 바뀌었다.)
* 멱등적 프로듀서 기능을 활성화 시키면 다음과 같은 것들이 바뀐다.
  * 프로듀서 ID를 받아오기 위해 프로듀서 시동 과정에서 API를 하나 더 호출한다.
  * 전송되는 각각의 레코드 배치에는 프로듀서 ID와 배치 내 첫 메시지의 시퀀스 넘버가 포함된다. (각 메시지의 시퀀스 넘버는 첫 메시지의 시퀀스 넘버 변화량을 더하면 나온다.)
  * 브로커들은 모든 프로듀서 인스턴스에서 들어온 레코드 배치의 시퀀스 넘버를 검증해서 메시지 중복을 방지한다.
  * 장애가 발생하더라도 각 파티션에 쓰여지는 메시지들의 순서는 보자오딘다. max.in.flight.requests.per.connection 설정값이 1보다 큰 값으로 잡혀도 마찬가지다. (5는 기본값인 동시에 멱등적 프로듀서가 지원하는 가장 큰 값이다.)

## 8.2 트랜잭션
* 트랜잭션 기능은 카프카 스트림즈를 사용해서 개발된 애플리케이션에 정확성을 보장하기 위해서 도입되었다.
  * 스트림 처리 애프릴케이션이 정확한 결과를 산출하도록 하기 위해, 각 입력 레코드는 정확히 한 번만 처리되어야 하며 그 처리 결과 역시 (장애 상황에서도) 정확히 한 번만 반영되어야 한다.
  * 카프카의 트랜잭션 기능은 스트림 처리 애플리케이션을 위해 기본 패턴인 '읽기-처리-쓰기' 패턴에서 사용하도록 개발되었다.
  * 트랜잭션 기능은 이런 맥락에서 '정확히 한 번'의미 구조를 보장할 수 있는 것이다.
  * 각 입력 레코드의 처리는 애플리케이션 내부 상태가 업데이트되고 결과가 출력 토픽에 성공적으로 쓰여졌을 때에야 완료된 것으로 간주된다.

### 8.2.2 트랜잭션이 해결하는 문제
#### 원본 토픽으로부터 이벤트를 읽어서, 처리를 한 다음, 결과를 다른 토픽에 쓰는 과정에서 각 메시지에 대한 결과가 정확히 한 번만 쓰여지도록 하는 과정에서 잘못될 수 있는 예시를 살펴보자.
1. 애플리케이션 크래시로 인한 재처리
* 원본 클러스터로부터 메시지를 읽어서 처리한 뒤, 애플리케이션은 두 가지를 해야 한다.
  * 결과를 출력 토픽에 쓰기
  * 읽어 온 메시지의 오프셋을 커밋하기
* 결과를 출력 토픽에는 썼는데 입력 오프셋은 커밋되기 전에 애플리케이션이 크래시가 발생하는 경우는 어떻게 될까?
  * 몇 초가 지난 후 하트비트가 끊어지면서 리밸런스가 발생하고, 컨슈머가 읽어오고 있던 파티션들은 다른 컨슈머로 재할당 된다.
  * 컨슈머는 새로 할당된 파티션의 마지막으로 커밋된 오프셋으로부터 레코드를 읽어오기 시작한다.
  * 마지막으로 커밋된 오프셋에서부터 크래시가 난 시점까지, 애플리케이션에 의해 처리된 모든 레코드들은 다시 처리될 것이며 결과 역시 출력 토픽에 다시 쓰여지기 때문에 중복이 발생한다.
2. 좀비 애플리케이션에 의해 발생하는 재처리
* 애플리케이션이 카프카로부터 레코드 배치를 읽어온 직후 뭔가를 하기 전에 멈추거나, 카프카로의 연결이 끊어진 경우
  * 하트비트가 끊어지면서 애플리케이션은 죽은 것으로 간주되어, 리밸런싱이 발생한다.
  * 파티션을 할당받은 새 컨슈머는 레코드 배치를 다시 읽어서 처리하고, 출력 토픽에 결과를 쓰는 동안에 이전에 멈췄던 애플리케이션이 다시 동작하게 되는 경우, 마지막으로 읽어 왔던 레코드 배치를 처리하고 결과를 출력 토픽에 쓸 수 있다.
  * 레코드를 읽어오기 위해 새로 카프카를 폴링하거나, 하트비트를 보냈다가 자기가 죽은 것으로 판정됐다는 것을 알아차릴 때까지 이 작업을 계속할 것이다.
* 스스로가 죽은 상태인지 모르는 컨슈머를 좀비라고 부른다.
* 이러한 상황에서 추가적인 보장이 없을 경우, 좀비에 의해 중복된 결과가 발생할 수 있다.

### 8.2.3 트랜잭션은 어떻게 '정확히 한 번'을 보장하는가?
* 카프카 트랜잭션은 메시지의 원자적 처리를 위해 원자적 다수 파티션 쓰기 기능을 도입했다.
* 트랜잭션을 사용해서 원자적 다수 파티션 쓰기를 수행하려면 트랜잭션적 프로듀서를 사용해야 한다.
  * 트랜잭션적 프로듀서와 보통 프로듀서의 차이점은 transactional.id 설정이 잡혀 있고 initTransactions()을 호출해서 초기화해주었다는 것뿐이다.
  * 카프카 브로커에 의해 자동으로 생성되는 producer.id 와는 달리 transactional.id 는 프로듀서 설정의 일부이며, 재시작을 하더라도 값이 유지된다.
  * transactional.id 의 주 용도는 재시작 후에도 동일한 프로듀서를 식별하는 것이다.
  * 카프카 브로커는 transactional.id 에서 producer.id 로의 대응 관계를 유지하고 있다가 만약 이미 있는 transactional.id 프로듀서가 initTransactions() 를 다시 호출하면 새로운 랜덤값이 아닌 이전에 쓰던 producer.id 값을 할당해준다.
* 애플리케이션의 좀비 인스턴스가 중복 프로듀서를 생성하는 것을 방지하려면 좀비 펜싱(zombie fencing), 혹은 애플리케이션의 좀비 인스턴스가 출력 스트림에 결과를 쓰는 것을 방지할 필요가 있다.
  * 일반적인 좀비 펜싱 방법은 에포크(epoch)를 사용하는 방식이 쓰인다.
  * 트랜잭션적 프로듀서가 초기화를 위해 initTransaction()를 호출하면 transactional.id 에 해당하는 에포크 값을 증가시킨다.
  * 오래된 프로듀서는 출력 스트림을 쓰는 것이 불가능하다.
* 트랜잭션은 대부분 프로듀서 쪽 기능이다.
  * 트랜잭션적 프로듀서를 생성하고, 트랜잭션을 시작하고, 다수의 파티션에 레코드를 쓰고, 이미 처리된 레코드들을 표시하기 위해 오프셋을 쓰고, 트랜잭션을 커밋하거나 중단하는 이 모든 작업이 프로듀서로부터 이루어진다.
  * 트랜잭션 기능을 사용해서 쓰여진 레코드는 결과적으로 중단된 트랜잭션에 속할지라도 다른 레코드들과 마찬가지로 파티션에 쓰여진다.
  * 컨슈머에 올바른 격리 수준이 설정되어 있지 않을 경우, '정확히 한 번' 보장은 이루어지지 않을 것이다.
* isolation.level 설정값을 잡아줌으로써 트랜잭션 기능을 써서 쓰여진 메시지들을 읽어오는 방식을 제어할 수 있따.
  * read_committed 로 설정된 경우, consumer.poll() 을 호출하면 커밋된 트랜잭션에 속한 메시지나 처음부터 트랜잭션에 속하지 않는 메시지만 리턴된다.
  * 기본값인 read_uncommitted 로 두면 진행중이거나 중단된 트랜잭션에 속하는 것들 포함, 모든 레코드가 리턴된다.
* 메시지의 읽기 순서를 보장하기 위해 read_committed 모드에서는 아직 진행중인 트랜잭션이 처음으로 시작된 시점(Last Stable Offset, LSO) 이후에 쓰여진 메시지는 리턴되지 않는다.
  * 이 메시지들은 트랜잭션이 프로듀서에 의해 커밋되거나 중단될 때까지, 혹은 transaction.timeout.ms(기본값: 15분) 설정값 만큼 시간이 지나 브로커가 트랜잭션을 중단시킬 때까지 보류된다.

### 8.2.4 트랜잭션으로 해결할 수 없는 문제들
1. 스트림 처리에 있어서의 부수 효과
* 스트림 처리 애플리케이션의 처리 단계에 사용자에게 이메일을 보내는 작업이 포함되어 있다고 가정
  * '정확히 한 번' 의미 구조를 활성화한다고 해서 이메일이 한 번만 발송되는 것은 아니다.
  * 이 기능은 카프카에 쓰여지는 레코드에만 적용된다.
  * 레코드 중복을 방지하기 위해 시퀀스 넘버를 사용하는 것이나 트랜잭션을 중단 혹은 취소하기 위해 마커를 사용하는 것은 카프카 안에서만 작동하는 것이다.
  * 스트림 처리 애플리케이션 안에서 외부 효과를 일으키는 작업에도 해당된다.

2. 카프카 토픽에서 읽어서 데이터베이스에 쓰는 경우
* 애플리케이션은 카프카가 아닌 외부 데이터베이스에 결과물을 쓰는 경우에 레코드는 데이터베이스에 쓰이고, 오프셋은 컨슈머에 의해 카프카에 커밋된다.
  * 하나의 트랜잭션에서 외부 데이터베이스에 결과를 쓰고 카프카에는 오프셋을 커밋할 수 있도록 해주는 매커니즘 같은건 없다.
* 마이크로서비스에서는 하나의 원자적 트랜잭션 안에서 데이터베이스도 업데이트하고 카프카에 메시지도 써야하는 경우가 종종 있다.
  * 이러한 경우 아웃 박스 패턴을 사용해서 해결할 수 있다.

3. 데이터베이스에서 읽어서, 카프카에 쓰고, 다시 다른 데이터베이스에 쓰는 경우
* 카프카 트랜잭션은 종단 보장에 필요한 기능을 가지고 있지 않다.

4. 한 클러스터에서 다른 클러스터로 데이터 복제
* 하나의 카프카 클러스터에서 다른 클러스터로 데이터를 복사할 때 '정확히 한 번'을 보장할 수 있다. (미러메이커 2.0을 통해서)
* 하지만 트랜잭션의 원자성을 보장하지는 않는다.
  * 애플리케이션이 여러 개의 레코드와 오프셋을 트랜잭션적으로 쓰고, 미러메이커가 이 레코드들을 다른 카프카 클러스터로 복사한다면, 복사 과정에서 트랜잭션 속성이나 보장 같은 것은 유실된다.

5. 발행/구독 패턴
* 컨슈머들이 커밋되지 않은 트랜잭션은 보이지 않도록 read_committed 설정이 되어야 있어야 한다.
  * 그렇지 않으면 '정확히 한 번'이 동작하지 않을 수 있다.

### 8.2.6 트랜잭션 ID와 펜싱
* 버전 2.5까지, 펜싱을 보장하는 유일한 방법은 트랜잭션 ID를 파티션에 정적으로 대응시켜 보는 것뿐이었다.
  * 각 파티션이 항상 단 하나의 트랜잭션 ID에 의해 읽혀짐은 보장할 수 있다.
  * 만약 트랜잭션 ID가 A인 프로듀서가 토픽 T에 메시지를 쓰다가 연결이 끊어지고, 트랜잭션 ID가 B인 새 프로듀서가 대신 들어올 경우, 연결이 복구된 A 쪽 프로듀서는 좀비지만 새 프로듀서와 트랜잭션 ID가 다르기 때문에 펜싱이 되지 않는다.
* 버전 2.5부터는 펜싱을 수행하는 방법으로 트랜잭션 ID와 컨슈머 그룹 메타데이터를 함께 사용한다.
  * 프로듀서의 오프셋 커밋 메서드를 호출할 때 단순한 컨슈머 그룹 ID가 아닌, 컨슈머 그룹 메타데이터를 인수로 전달한다.

### 8.2.7 트랜잭션의 작동 원리
* 카프카 트랜잭션 기능의 기본적인 알고리즘은 찬디-램포트 스냅샷 알고리즘의 영향을 받았다.
  * 이 알고리즘은 통신 채널을 통해 '마커(marker)'라 불리는 컨트롤 메시지를 보내고, 이 마커의 도착을 기준으로 일관적인 상태를 결정한다.
* 카프카의 트랜잭션은 다수의 파티션에 대해 트랜잭션이 커밋되거나 중단되었다는 것을 표시하기 위해 마커 메시지를 사용한다.
  * 프로듀서가 트랜잭션을 커밋하기 위해 트랜잭션 코디네이터에게 '커밋' 메시지를 보내면 트랜잭션 코디네이터가 트랜잭션에 관련된 모든 파티션에 커밋 마커를 쓴다.
* 만약 일부 파티션에만 커밋 메시지가 쓰여진 상태에서 프로듀서가 크래시 나면 어떻게 될까?
  * 카프카 트랜잭션은 2단계 커밋(two-phase commit)과 트랜잭션 로그를 사용해서 이 문제를 해결한다.
1. 현재 진행중인 트랜잭션이 존재함을 로그에 기록한다. 연관된 파티션들 역시 함께 기록한다.
2. 로그에 커밋 혹은 중단 시도를 기록한다. (로그에 기록이 남으면 최종적으로는 커밋되거나 종단되어야 ㅎ나다.)
3. 모든 파티션에 트랜잭션 마커를 쓴다.
4. 트랜잭션이 종료되었음을 로그에 쓴다.
* 위의 기본적인 알고리즘을 구현하기 위해 카프카는 트랜잭션 로그를 사용하고, __transaction_state 라는 이름의 내부 토픽을 사용한다.

## 8.3 트랜잭션 성능
* 트랜잭션은 프로듀서에 약간의 오버헤드를 발생시킨다.
  * 프로듀서를 생성해서 사용하는 동안 트랜잭션 ID 등록 요청은 단 한 번 발생한다.
  * 트랜잭션의 일부로서 파티션들을 등록하는 추가적인 호출은 각 트랜잭션에 있어서 파티션 별로 최대 한 번씩만 이루어진다.
  * 각 트랜잭션이 커밋 요청을 전송하면, 파티션마다 커밋 마커가 추가된다.
  * 트랜잭션 초기화와 커밋 요청은 동기적으로 작동하기 때문에 성공적으로 완료되거나, 실패하거나, 타임아웃되거나 할 때까지 어떤 데이터도 전송되지 않는다.
  * 그렇기 때문에 오버헤드는 더 증가한다.
* 프로듀서에 있어서 트랜잭션 오버헤드는 트랜잭션에 포함된 메시지의 수와는 무관하다.
  * 따라서 트랜잭션마다 많은 수의 메시지를 집어넣는 쪽이 상대적으로 오버헤드가 적을 뿐 아니라 동기적으로 실행되는 단계의 수도 줄어든다.
  * 결과적으로 전체 처리량은 올라간다.
* 컨슈머 쪽에 대해서는, 커밋 마커를 읽어오는 작업에 관련해서 약간의 오버헤드가 있다.
  * 트랜잭션 기능이 컨슈머 성능에 미치는 핵심적인 영향은 read_committed 모드 컨슈머에서는 아직 완료되지 않은 트랜잭션의 레코드들이 리턴되지 않는다는 것이다.
  * 트랜잭션 커밋 사이의 간격이 길어질수록 컨슈머는 메시지가 리턴될 때까지 오랫동안 대기해야 한다.
  * 결과적으로 종단 지연 역시 그만큼 길어진다.
